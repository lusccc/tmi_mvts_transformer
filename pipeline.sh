
dataset='SHL'

python main.py --output_dir experiments --comment "pretraining through trj_denoising_imputation" --name ${dataset}_trj_pretrained_denoi_imp --task denoising_imputation_pretrain --records_file Denoising_imputation_records.xls --data_class trajectory --data_name ${dataset} --val_ratio 0.1 --test_ratio 0.2 --epochs 50 --lr 0.001 --optimizer RAdam --batch_size 1000 --pos_encoding learnable --num_workers 24 --d_model 128  --num_heads 8 --num_layers 3 --dim_feedforward 256  --input_type mix
sleep 5s
python main.py --output_dir experiments --comment "pretraining through feat_denoising_imputation" --name ${dataset}_feature_pretrained_denoi_imp --task denoising_imputation_pretrain --records_file Denoising_imputation_records.xls --data_class feature --data_name ${dataset} --val_ratio 0.1 --test_ratio 0.2 --epochs 300 --lr 0.001 --optimizer RAdam --batch_size 1000 --pos_encoding learnable --d_model 64 --num_workers 24 --d_model 128  --num_heads 8 --num_layers 3 --dim_feedforward 256  --input_type mix
sleep 5s
python main.py --output_dir experiments --comment "finetune for classification" --name ${dataset}_dual_branch_finetune_trj_denoi_imp_mf_denoi_imp --task dual_branch_classification --records_file Classification_records.xls --data_class trajectory_with_feature --data_name ${dataset} --val_ratio 0.1 --test_ratio 0.2 --epochs 300 --lr 0.001 --optimizer RAdam --batch_size 550 --pos_encoding learnable --num_workers 24  --input_type mix --change_output --key_metric accuracy --feature_branch_hyperparams experiments/tmp/feature_model_hyperparams.json --trajectory_branch_hyperparams experiments/tmp/trajectory_model_hyperparams.json --load_feature_branch experiments/tmp/feature_model_best.pth --load_trajectory_branch experiments/tmp/trajectory_model_best.pth
sleep 5s


#-----
#python src/main.py --output_dir experiments --comment "pretraining through trj_denoising_imputation" --name ${dataset}_trj_pretrained_only_denoi --task denoising_pretrain --records_file Denoising_imputation_records.xls --data_class trajectory --data_name ${dataset} --val_ratio 0.1 --test_ratio 0.2 --epochs 20 --lr 0.001 --optimizer RAdam --batch_size 900 --pos_encoding learnable --num_workers 16 --d_model 64  --num_heads 8 --num_layers 4 --dim_feedforward 256  --input_type mix
#sleep 5s
#python src/main.py --output_dir experiments --comment "pretraining through feat_denoising" --name ${dataset}_feature_pretrained_only_denoi --task denoising_pretrain --records_file Denoising_imputation_records.xls --data_class feature --data_name ${dataset} --val_ratio 0.1 --test_ratio 0.2 --epochs 50 --lr 0.001 --optimizer RAdam --batch_size 900 --pos_encoding learnable --d_model 64 --num_workers 16 --num_heads 8 --num_layers 4 --dim_feedforward 256  --input_type mix
#sleep 5s
#python src/main.py --output_dir experiments --comment "finetune for classification" --name ${dataset}_dual_branch_finetune_trj_denoi_mf_denoi --task dual_branch_classification --records_file Classification_records.xls --data_class trajectory_with_feature --data_name ${dataset} --val_ratio 0.1 --test_ratio 0.2 --epochs 100 --lr 0.001 --optimizer RAdam --batch_size 550 --pos_encoding learnable --num_workers 16  --input_type mix --change_output --key_metric accuracy --feature_branch_hyperparams experiments/tmp/feature_model_hyperparams.json --trajectory_branch_hyperparams experiments/tmp/trajectory_model_hyperparams.json --load_feature_branch experiments/tmp/feature_model_best.pth --load_trajectory_branch experiments/tmp/trajectory_model_best.pth

#test
python main.py --output_dir test_res --comment "finetune for classification" --name ${dataset}_dual_branch_finetune_test --task dual_branch_classification --records_file Classification_records.xls --data_class trajectory_with_feature --data_name ${dataset} --val_ratio 0.1 --test_ratio 0.2 --epochs 200 --lr 0.001 --optimizer RAdam --batch_size 400 --pos_encoding learnable --num_workers 24 --key_metric accuracy --feature_branch_hyperparams experiments/tmp/feature_model_hyperparams.json --trajectory_branch_hyperparams experiments/tmp/trajectory_model_hyperparams.json --load_model ./experiments/611midnight_repeat0_SHL_dual_branch_finetune_trj_denoising_imputation_pretrain_feat_denoising_imputation_pretrain_2022-06-11_02-37-14_ODR/checkpoints/model_best.pth  --input_type mix --test_only testset

#single branch test
python src/main.py --output_dir test_res --comment "finetune for classification" --name ${dataset}_dual_branch_finetune_test --task feature_branch_classification_from_scratch --records_file Classification_records.xls --data_class feature --data_name ${dataset} --val_ratio 0.1 --test_ratio 0.2 --epochs 200 --lr 0.001 --optimizer RAdam --batch_size 400 --pos_encoding learnable --num_workers 16 --key_metric accuracy --feature_branch_hyperparams experiments/tmp/feature_model_hyperparams.json --trajectory_branch_hyperparams experiments/tmp/trajectory_model_hyperparams.json --load_model history_exps/experiments_20220609/603night_SHL_feature3,4,5,8_classification_scratch_2022-06-03_03-44-00_7f3/checkpoints/model_best.pth  --input_type noise --test_only testset

#tmp
#python src/main.py --output_dir experiments --comment "finetune for classification" --name ${dataset}_dual_branch_finetune_freeze --task dual_branch_classification --records_file Classification_records.xls --data_class trajectory_with_feature --data_name ${dataset} --val_ratio 0.1 --test_ratio 0.2 --epochs 100 --lr 0.001 --optimizer RAdam --batch_size 450 --pos_encoding learnable --num_workers 16  --input_type mix --change_output --key_metric accuracy --feature_branch_hyperparams experiments/tmp/feature_model_hyperparams.json --trajectory_branch_hyperparams experiments/tmp/trajectory_model_hyperparams.json --load_feature_branch experiments/geolife_feature_pretrained_2022-05-10_13-31-55_g5t/checkpoints/model_best.pth --load_trajectory_branch experiments/geolife_trj_pretrained_2022-05-10_13-25-17_ezt/checkpoints/model_best.pth --freeze

#python src/main.py --output_dir experiments --comment "finetune for classification" --name ${dataset}_dual_branch_finetune_trj_denoi_mf_denoi --task dual_branch_classification --records_file Classification_records.xls --data_class trajectory_with_feature --data_name ${dataset} --val_ratio 0.1 --test_ratio 0.2 --epochs 100 --lr 0.001 --optimizer RAdam --batch_size 600 --pos_encoding learnable --num_workers 16  --input_type mix --change_output --key_metric accuracy --feature_branch_hyperparams experiments/tmp/feature_model_hyperparams.json --trajectory_branch_hyperparams experiments/tmp/trajectory_model_hyperparams.json --load_feature_branch experiments/geolife_feature_pretrained_only_denoi_2022-05-11_02-06-38_M4E/checkpoints/model_best.pth --load_trajectory_branch experiments/geolife_trj_pretrained_only_denoi_2022-05-11_01-58-09_3Nk/checkpoints/model_best.pth
#
#
#python src/main.py --output_dir experiments --comment "pretraining through feat_denoising_imputation" --name ${dataset}_feature_pretrained --task denoising_imputation_pretrain --records_file Denoising_imputation_records.xls --data_class feature --data_name ${dataset} --val_ratio 0.1 --test_ratio 0.2 --epochs 50 --lr 0.001 --optimizer RAdam --batch_size 1000 --pos_encoding learnable --d_model 64 --num_workers 16 --num_heads 8 --num_layers 4 --dim_feedforward 256  --input_type mix

